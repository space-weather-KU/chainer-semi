# 学習済みモデルをファイルにセーブ・ロードする方法
公式bookの1/2/10


長時間かかる学習をする上では、学習の途中経過を保存して、再利用することが必須のテクニックとなります。
以下に、MNISTで数字認識を学習し、mnist.modelとして保存する例を示します。

## このプログラムの使い方 

まとめてくれた円尾さん、ありがとう！


1. ひとつめのプログラムを、ファイル名learn.pyとし、パソコンに保存する。
2. プログラムを実行する。(`python learn.py`)
　→これでmnist.modelというファイルが作られる
3. 二つ目のプログラムを、ファイル名number.pyとし、パソコンに保存する
4. 数字が描かれた画像をひとつ作る。(28x28ピクセルの解像度で)
5. プログラムを写真の画像とともに実行する。(`python number.py <画像ファイル名>`)
6. 出力例として以下のようなものが出力されます。
```
[[-6.724751    2.46975136 -3.50075865 -4.9167695   0.36070192 -6.33550215
  -5.33270979  8.72220802 -4.02996731 -2.73090959]]
The given image is  7
```
10個の数字は、それぞれ画像が0..9までであると判定された度合い（大きいほど強い）で、最後の行は「入力画像を７だと判定した！」ということを表しています。





```python
import chainer
from chainer import datasets
from chainer import serializers
from chainer import links as L
from chainer import functions as F
from chainer import Variable, optimizers
import numpy as np




class MLP(chainer.Chain):


    def __init__(self, n_units, n_out):
        super(MLP, self).__init__(
            # the size of the inputs to each layer will be inferred
            l1=L.Linear(None, n_units),  # n_in -> n_units
            l2=L.Linear(None, n_units),  # n_units -> n_units
            l3=L.Linear(None, n_out),  # n_units -> n_out
        )


    def __call__(self, x):
        h1 = F.relu(self.l1(x))
        h2 = F.relu(self.l2(h1))
        return self.l3(h2)


batchsize = 100
train, test = chainer.datasets.get_mnist()
train_iter = chainer.iterators.SerialIterator(train, batchsize)
test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)


model = MLP(784, 10)
opt = chainer.optimizers.Adam()
opt.use_cleargrads()
opt.setup(model)


train_num = len(train)
test_num = len(test)


epoch_num = 10
for epoch in xrange(epoch_num):
    train_loss_sum = 0
    train_accuracy_sum = 0
    for i in xrange(0, train_num, batchsize):
        batch = train_iter.next()
        x = Variable(np.asarray([s[0] for s in batch]))
        t = Variable(np.asarray([s[1] for s in batch]))
        y = model(x)
        loss = F.softmax_cross_entropy(y, t)
        model.cleargrads()
        loss.backward()
        opt.update()
        train_loss_sum += loss.data
        train_accuracy_sum += F.accuracy(y, t).data
    print(train_loss_sum, train_accuracy_sum)
    serializers.save_npz('mnist.model', model)
```


以下は、保存されたモデルを使って、数字の描かれた画像を認識するプログラムです！

```python
# -*- coding: utf-8 -*-"


import chainer
from chainer import datasets
from chainer import serializers
from chainer import links as L
from chainer import functions as F
from chainer import Variable, optimizers
import numpy as np
import scipy.ndimage as ndimage
import sys




class MLP(chainer.Chain):
    def __init__(self, n_units, n_out):
        super(MLP, self).__init__(
            # the size of the inputs to each layer will be inferred
            l1=L.Linear(None, n_units),  # n_in -> n_units
            l2=L.Linear(None, n_units),  # n_units -> n_units
            l3=L.Linear(None, n_out),  # n_units -> n_out
        )


    def __call__(self, x):
        h1 = F.relu(self.l1(x))
        h2 = F.relu(self.l2(h1))
        return self.l3(h2)


def MLP_response_to_label(y):
    return np.argmax(y[0])




batchsize = 100
train, test = chainer.datasets.get_mnist()
train_iter = chainer.iterators.SerialIterator(train, batchsize)
test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)


model = MLP(784, 10)


# load the model from the saved learning
serializers.load_npz('mnist.model', model)


# load the given image
img = ndimage.imread(sys.argv[1],flatten=True)
img = ((255 - img)/255.0).astype(np.float32)
the_img = img.reshape((1,784))


x = Variable(the_img)


the_y = model(x)
print the_y.data
print "The given image is ", MLP_response_to_label(the_y.data)
```



